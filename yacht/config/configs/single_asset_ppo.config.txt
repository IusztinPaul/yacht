input: {
    market: 'Yahoo'
    dataset: 'DayMultiFrequencyDataset'
    price_normalizer: 'IdentityNormalizer' # Broken. Don't use until fix.
    other_normalizer: 'IdentityNormalizer' # Broken. Don't use until fix.
    tickers: ['BTC-USD', 'ETH-USD', 'LTC-USD', 'DOGE-USD', 'XRP-USD', 'DASH-USD', 'XMR-USD']
    intervals: ['1d']
    features: ['Close', 'Open', 'High', 'Low', 'Volume']
    technical_indicators: ['macd', 'rsi_30', 'cci_30', 'dx_30']
    start: '1/1/2015'
    end: '1/8/2021'
    window_size: 1
    include_weekends: true
    backtest_split_ratio: 0.27
    backtest_embargo_ratio: 0.03
    backtest: {
        run: true
        deterministic: false
        tickers: ['BTC-USD']
        n_runs: 4
    }
}
environment: {
    name: 'SingleAssetEnvironment-v0'
    n_envs: 4
    envs_on_different_processes: false
    buy_commission: 0.00
    sell_commission: 0.00
    initial_cash_position: 1000000
    reward_schemas: [
    {
        name: 'AssetsPriceChangeRewardSchema'
        reward_scaling: 0.0001
    },
    {
        name: 'ActionMagnitudeRewardSchema',
        reward_scaling: 0.0001
    }
    ]
    action_schema: 'ContinuousFloatActionSchema'
    max_units_per_asset: 100
}
agent: {
    name: 'PPO'
    verbose: true
    policy: {
        name: 'MlpPolicy'
        activation_fn: 'Tanh',
        net_arch: {
            shared: [128]
            vf: [64, 64]
            pi: [64, 64]
        }
    }
}
train: {
    trainer_name: 'NoEvalTrainer'
    total_timesteps: 10000
    collecting_n_steps: 2500
    learning_rate: 0.00025
    batch_size: 2500
    n_epochs: 10
    gamma: 0.99
    gae_lambda: 0.95
    clip_range: 0.2
    entropy_coefficient: 0.01,
    vf_coefficient: 0.5
    max_grad_norm: 0.5
    use_sde: false
    sde_sample_freq: -1
    k_fold_splits: 3
    k_fold_purge_ratio: 0.03
    k_fold_embargo_ratio: 0.01
}
meta: {
    device: 'gpu'
    experiment_tracker: 'wandb'
}