input: {
    market: 'Binance'
    dataset: 'DayForecastDataset'
    price_normalizer: 'IdentityNormalizer'
    other_normalizer: 'IdentityNormalizer'
    tickers: ['BTC']
    intervals: ['1d', '6h', '1h']
    features: ['Close', 'Volume']
    technical_indicators: ['macd','boll_ub','boll_lb','rsi_30', 'cci_30', 'dx_30','close_30_sma','close_60_sma']
    start: '18/8/2017'
    end: '1/1/2021'
    back_test_split_ratio: 0.4
    back_test_embargo_ratio: 0.03
    window_size: 1
}
environment: {
    name: 'DayForecastEnv-v0'
    reward_schemas: [
    {
        name: 'PriceChangeRewardSchema'
        reward_scaling: 0.0001
    },
    {
        name: 'LeaderBoardRewardSchema'
        density_thresholds: [
            0.01, 0.02, 0.03, 0.04, 0.05, 0.075, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.48, 0.49, 0.5,
            0.5, 0.51, 0.52, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.925, 0.95, 0.96, 0.97, 0.98, 0.99
        ]
    }
    ]
    action_schema: 'ContinuousActionScheme'
    max_units_per_asset: 10000
}
agent: {
    name: 'PPO'
    verbose: true
    policy: {
        name: 'MlpPolicy'
        activation_fn: 'ReLU',
        feature_extractor: {
            name: 'MultipleTimeFramesFeatureExtractor'
            features_dim: [64, 64],
            drop_out_p: 0.25
        }
        net_arch: {
            shared: [32]
            vf: [8]
            pi: [8]
        }
    }
}
train: {
    trainer_name: 'NoEvalTrainer'
    collect_n_times: 100
    collecting_n_steps: 739
    learning_rate: 0.0001
    batch_size: 739
    n_epochs: 3
    gamma: 0.9
    gae_lambda: 0.95
    clip_range: 0.2
    entropy_coefficient: 0.01,
    vf_coefficient: 0.5
    max_grad_norm: 0.5
    k_fold_splits: 3
    k_fold_purge_ratio: 0.03
    k_fold_embargo_ratio: 0.01
    eval_frequency: 1
    log_frequency: 1
}
meta: {
    device: 'gpu'
    backtest: true,
    experiment_tracker: 'wandb'
}